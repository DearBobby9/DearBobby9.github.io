## Abstract

This paper studies whether AR-embedded visualizations can improve how people rely on AI during spatial decision-making. We compare an embedded AR X-ray view against a traditional 2D minimap in AI-assisted, time-critical target-selection tasks. In a user study with 32 participants, the AR-embedded condition unexpectedly produced more inappropriate reliance (mainly over-reliance), while still showing advantages for spatial mapping.

## Why This Question Matters

AI and indoor sensing systems can guide users in complex spaces, but people still need to judge when AI is reliable. If a visualization format increases blind trust, decision quality can drop even when the interface looks more "immersive."

## Study Setup

- **Task type:** AI-assisted spatial target selection under time pressure
- **Comparison:** AR embedded X-ray vs. 2D minimap
- **Participants:** 32
- **Goal:** Measure whether visualization style affects appropriate vs. inappropriate reliance

## Key Findings

- Embedded AR views did **not automatically** produce better reliance calibration.
- Over-reliance increased in the AR embedded condition.
- Contributing factors included perceptual challenges and visual proximity illusions.
- Despite that, embedded visualization helped with spatial mapping and environmental understanding.

## Key Contributions

- Empirical evidence on how visualization modality shapes reliance behavior in AR+AI workflows.
- A direct comparison of embedded AR visualization and 2D minimap in the same decision context.
- Design implications for building AR interfaces that support calibrated human-AI collaboration.

## Design Implications

- Do not assume higher realism leads to more appropriate trust.
- Pair embedded visual cues with uncertainty communication and cross-check support.
- Evaluate reliance outcomes directly (not only speed/accuracy) when designing AR decision aids.

## Video / Demo

Demo video and supplemental materials will be added here.
